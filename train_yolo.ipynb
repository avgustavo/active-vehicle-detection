{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef95c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from lightly.api import ApiWorkflowClient\n",
    "from ultralytics import YOLO\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87f2667",
   "metadata": {},
   "source": [
    "Exportar arquivos do Lightly para cada ciclo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74e71331",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIGHTLY_TOKEN = \"6ef4b5e20f6a1dba87a72a9eb4ddceb3f9529cd3d46b94a8\" \n",
    "DATASET_NAME = \"Teste_proportion2\"\n",
    "DATASET_PATH = 'FOCAL/yolov5_format/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac7c5276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciclo5\n",
      "ciclo4\n",
      "ciclo3\n",
      "ciclo2\n",
      "ciclo1\n",
      "initial-tag\n"
     ]
    }
   ],
   "source": [
    "# Create the LightlyOne client to connect to the API.\n",
    "client = ApiWorkflowClient(token=LIGHTLY_TOKEN)\n",
    "client.set_dataset_id_by_name(dataset_name=DATASET_NAME)\n",
    "\n",
    "# Get all the tags for this dataset\n",
    "tags = client.get_all_tags()\n",
    "\n",
    "# Loop over tags and export the filenames\n",
    "# Note: first tag in `tags` is the newest one \n",
    "#       and the last one is always `initial-tag`\n",
    "tag_files = []\n",
    "for tag in tags:\n",
    "    print(tag.name)\n",
    "    image_names = client.export_filenames_by_tag_name(\n",
    "        tag_name=tag.name  # name of the tag in the dataset\n",
    "    )\n",
    "    file_name = f\"{tag.name}.txt\"\n",
    "    file_path = DATASET_PATH + \"/\" + file_name\n",
    "    \n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(image_names)\n",
    "    tag_files.append(file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e2729665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lightly_init(dataset_name, token=LIGHTLY_TOKEN):\n",
    "    \"\"\"\n",
    "    Inicializa o cliente lightl, define o dataset a ser utilizado\n",
    "    \n",
    "    Args: \n",
    "        token (str): Token de autenticação do cliente Lightly,\n",
    "        dataset_name (str): Nome do dataset\n",
    "    \"\"\"\n",
    "    #iniciar o cliente e setar dataset\n",
    "    client = ApiWorkflowClient(token=LIGHTLY_TOKEN)\n",
    "    client.set_dataset_id_by_name(dataset_name=dataset_name)\n",
    "\n",
    "    # Pegando todas as tags\n",
    "    tags = client.get_all_tags()\n",
    "\n",
    "    # Ordenando na ordem correta de ciclos e tirando o initial-tag\n",
    "    tags.reverse()\n",
    "    tags.pop(0)\n",
    "\n",
    "    '''\n",
    "    Para cada tag, criar o arquivo de texto acumulado com os nomes no DATASET_PATH,\n",
    "    pois necessita para o arquivo de configuração do YOLO.    \n",
    "    '''\n",
    "    tag_files = []\n",
    "    image_names = ''\n",
    "    for tag in tags:\n",
    "        print(tag.name)\n",
    "        if image_names == '':\n",
    "            image_names = client.export_filenames_by_tag_name(tag_name=tag.name)\n",
    "        else:\n",
    "            # Adiciona uma nova linha antes de adicionar os nomes da próxima tag\n",
    "            image_names += '\\n' + client.export_filenames_by_tag_name(tag_name=tag.name)\n",
    "\n",
    "        file_path = DATASET_PATH + \"/\" + f\"{tag.name}.txt\"\n",
    "        \n",
    "        with open(file_path, \"w\") as f:\n",
    "            f.write(image_names)\n",
    "        tag_files.append(file_path)\n",
    "\n",
    "    print(f\"Arquivos de texto criados! =D\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "05960a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ciclo1\n",
      "ciclo2\n",
      "ciclo3\n",
      "ciclo4\n",
      "ciclo5\n",
      "Arquivos de texto criados! =D\n"
     ]
    }
   ],
   "source": [
    "lightly_init(DATASET_NAME, LIGHTLY_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24efbb18",
   "metadata": {},
   "source": [
    "Inverter a lista de arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2242d021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['initial-tag.txt',\n",
       " 'ciclo1.txt',\n",
       " 'ciclo2.txt',\n",
       " 'ciclo3.txt',\n",
       " 'ciclo4.txt',\n",
       " 'ciclo5.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_files.reverse()\n",
    "tag_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f12ff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tag files: ['ciclo1.txt', 'ciclo2.txt', 'ciclo3.txt', 'ciclo4.txt', 'ciclo5.txt']\n"
     ]
    }
   ],
   "source": [
    "tag_files.pop(0)  # remove the initial tag file\n",
    "print(f\"Tag files: {tag_files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e60c83",
   "metadata": {},
   "source": [
    "#### Com base nos fileNames, para cada iteração vamos\n",
    "1. Treinar o modelo com base nos filenames de cada ciclo\n",
    "2. Salvar o histórico de treinamento\n",
    "3. Salvar as métricas de avaliação do modelo\n",
    "4. Salvar o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93591dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_yolo_dataset(cycle_name: str, file: str, dataset_path: str):\n",
    "    \n",
    "    output_dir = Path(f\"config/{cycle_name}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)    \n",
    "    # img_out = output_dir / \"images\" / \"train\"\n",
    "    # lbl_out = output_dir / \"labels\" / \"train\"\n",
    "    # img_out.mkdir(parents=True, exist_ok=True)\n",
    "    # lbl_out.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # for path in frame_paths:\n",
    "    #     img_path = Path(dataset_path) / path\n",
    "    #     lbl_path = Path(labels_path) / path.with_suffix(\".txt\").name\n",
    "\n",
    "    #     shutil.copy(img_path, img_out / img_path.name)\n",
    "    #     shutil.copy(lbl_path, lbl_out / lbl_path.name)\n",
    "\n",
    "    # Criando o data.yaml\n",
    "    yaml = f\"\"\"\n",
    "path: {dataset_path}\n",
    "train: {file}\n",
    "val: val \n",
    "test: test\n",
    "nc: 80\n",
    "names:\n",
    "  0: person\n",
    "  1: bicycle\n",
    "  2: car\n",
    "  3: motorcycle\n",
    "  4: airplane\n",
    "  5: bus\n",
    "  6: train\n",
    "  7: truck\n",
    "  8: boat\n",
    "  9: traffic light\n",
    "  10: fire hydrant\n",
    "  11: stop sign\n",
    "  12: parking meter\n",
    "  13: bench\n",
    "  14: bird\n",
    "  15: cat\n",
    "  16: dog\n",
    "  17: horse\n",
    "  18: sheep\n",
    "  19: cow\n",
    "  20: elephant\n",
    "  21: bear\n",
    "  22: zebra\n",
    "  23: giraffe\n",
    "  24: backpack\n",
    "  25: umbrella\n",
    "  26: handbag\n",
    "  27: tie\n",
    "  28: suitcase\n",
    "  29: frisbee\n",
    "  30: skis\n",
    "  31: snowboard\n",
    "  32: sports ball\n",
    "  33: kite\n",
    "  34: baseball bat\n",
    "  35: baseball glove\n",
    "  36: skateboard\n",
    "  37: surfboard\n",
    "  38: tennis racket\n",
    "  39: bottle\n",
    "  40: wine glass\n",
    "  41: cup\n",
    "  42: fork\n",
    "  43: knife\n",
    "  44: spoon\n",
    "  45: bowl\n",
    "  46: banana\n",
    "  47: apple\n",
    "  48: sandwich\n",
    "  49: orange\n",
    "  50: broccoli\n",
    "  51: carrot\n",
    "  52: hot dog\n",
    "  53: pizza\n",
    "  54: donut\n",
    "  55: cake\n",
    "  56: chair\n",
    "  57: couch\n",
    "  58: potted plant\n",
    "  59: bed\n",
    "  60: dining table\n",
    "  61: toilet\n",
    "  62: tv\n",
    "  63: laptop\n",
    "  64: mouse\n",
    "  65: remote\n",
    "  66: keyboard\n",
    "  67: cell phone\n",
    "  68: microwave\n",
    "  69: oven\n",
    "  70: toaster\n",
    "  71: sink\n",
    "  72: refrigerator\n",
    "  73: book\n",
    "  74: clock\n",
    "  75: vase\n",
    "  76: scissors\n",
    "  77: teddy bear\n",
    "  78: hair drier\n",
    "  79: toothbrush\n",
    "\"\"\".strip()\n",
    "\n",
    "    with open(output_dir / \"data.yaml\", \"w\") as f:\n",
    "        f.write(yaml)\n",
    "\n",
    "    return output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afbd26bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_yolo(cycle_name, data_yaml_path, epochs=20):\n",
    "    \n",
    "    #Carregar modelo\n",
    "    model = YOLO('yolo11n.pt')\n",
    "\n",
    "    #Treinar modelo\n",
    "    results = model.train(\n",
    "        data=data_yaml_path,\n",
    "        epochs=epochs,\n",
    "        name=f\"{cycle_name}\",\n",
    "        project=\"lightly_selection2\",\n",
    "        # device=[0, 1]\n",
    "    )\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "382d235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qtd de linhas: 34\n",
      "\n",
      "🚀 Preparando ciclo ciclo1 com 34 imagens\n",
      "New https://pypi.org/project/ultralytics/8.3.168 available 😃 Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.167 🚀 Python-3.10.12 torch-2.7.0+cu126 CPU (13th Gen Intel Core(TM) i7-1355U)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=config/ciclo1/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=1, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=ciclo1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=lightly_selection2, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=lightly_selection2/ciclo1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    464912  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLO11n summary: 181 layers, 2,624,080 parameters, 2,624,064 gradients, 6.6 GFLOPs\n",
      "\n",
      "Transferred 499/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "WARNING ⚠️ \u001b[34m\u001b[1mtrain: \u001b[0mImage speed checks: failed to access files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning dress... 0 images, 0 backgrounds, 34 corrupt: 100%|██████████| 34/34 [00:00<00:00, 73131.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mdress/35f5fecb-755a-45d6-ac3d-3feb8299dc87.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'dress/35f5fecb-755a-45d6-ac3d-3feb8299dc87.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mdress/7a80fe51-8dfd-4e62-a65a-b192365731fa.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'dress/7a80fe51-8dfd-4e62-a65a-b192365731fa.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mdress/be545b93-c60d-4be6-ae3a-64efd37b7fee.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'dress/be545b93-c60d-4be6-ae3a-64efd37b7fee.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mhat/7c28df10-5bfc-4deb-b57f-6c292f07b98b.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'hat/7c28df10-5bfc-4deb-b57f-6c292f07b98b.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mhat/d7c07f9f-8362-4abc-92aa-193221a7db5b.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'hat/d7c07f9f-8362-4abc-92aa-193221a7db5b.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mlongsleeve/0354015d-9ed3-4175-9f85-dd5725dce0e1.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'longsleeve/0354015d-9ed3-4175-9f85-dd5725dce0e1.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mlongsleeve/2b12ad64-97e5-4500-ad2e-f74ea31eacbb.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'longsleeve/2b12ad64-97e5-4500-ad2e-f74ea31eacbb.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mlongsleeve/5e1c56ce-c32c-4056-9278-864773ae2024.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'longsleeve/5e1c56ce-c32c-4056-9278-864773ae2024.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mlongsleeve/7a20924e-30a3-49e9-8d9f-417c163ea444.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'longsleeve/7a20924e-30a3-49e9-8d9f-417c163ea444.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mlongsleeve/7e43962c-1287-4463-b6bd-964fefe51a32.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'longsleeve/7e43962c-1287-4463-b6bd-964fefe51a32.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mlongsleeve/9cb4943a-cf4b-467e-b39e-e4694d498fb2.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'longsleeve/9cb4943a-cf4b-467e-b39e-e4694d498fb2.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mlongsleeve/cbb2e29f-ac73-408c-834c-3c8ae1bd0ac7.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'longsleeve/cbb2e29f-ac73-408c-834c-3c8ae1bd0ac7.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mlongsleeve/dbd42bc7-1819-49bf-83b0-30844e9bc344.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'longsleeve/dbd42bc7-1819-49bf-83b0-30844e9bc344.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mlongsleeve/e01b05a4-e4ac-40cb-8049-0a3781971796.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'longsleeve/e01b05a4-e4ac-40cb-8049-0a3781971796.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0moutwear/42518e91-c969-49f5-ac68-dfe394d7451e.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'outwear/42518e91-c969-49f5-ac68-dfe394d7451e.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0moutwear/446df066-edee-4c69-90d7-5013bcc72cf2.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'outwear/446df066-edee-4c69-90d7-5013bcc72cf2.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0moutwear/6e28fa59-5fe0-418a-ab6a-9b7e1cc9972a.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'outwear/6e28fa59-5fe0-418a-ab6a-9b7e1cc9972a.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mpants/19ff0603-c52b-4d27-a9b9-cfd9da5e9f35.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'pants/19ff0603-c52b-4d27-a9b9-cfd9da5e9f35.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mpants/47106cae-9eee-4147-bcd1-458f2f00fd3d.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'pants/47106cae-9eee-4147-bcd1-458f2f00fd3d.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mpants/4cc4e673-fecd-4e4e-a7eb-f2efd39a5291.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'pants/4cc4e673-fecd-4e4e-a7eb-f2efd39a5291.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mpants/ce627dae-599a-4aa4-915d-0d5a32737292.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'pants/ce627dae-599a-4aa4-915d-0d5a32737292.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mshirt/00143901-a14c-4600-960f-7747b4a3a8cd.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'shirt/00143901-a14c-4600-960f-7747b4a3a8cd.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mshirt/a85064d6-0f5d-4fce-9e3a-d1b5902c6098.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'shirt/a85064d6-0f5d-4fce-9e3a-d1b5902c6098.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mshirt/cad0e833-619e-4517-91ce-938497622c12.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'shirt/cad0e833-619e-4517-91ce-938497622c12.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mshoes/24535295-abe3-4613-91f6-a7fe87954662.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'shoes/24535295-abe3-4613-91f6-a7fe87954662.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mshoes/253dc2b9-f49e-4f55-9917-c9005c29bbd9.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'shoes/253dc2b9-f49e-4f55-9917-c9005c29bbd9.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mshoes/6cb6102f-cf2a-4b60-8b44-97e8b8e1e4f2.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'shoes/6cb6102f-cf2a-4b60-8b44-97e8b8e1e4f2.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mshoes/7bb0226b-f068-4b46-9e40-1e5110319fcd.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'shoes/7bb0226b-f068-4b46-9e40-1e5110319fcd.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mshoes/7d5a20ff-6431-404e-9870-78140166cf7a.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'shoes/7d5a20ff-6431-404e-9870-78140166cf7a.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mskirt/4d5d201a-11cb-4e5c-b291-9b8c833c4ddf.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 'skirt/4d5d201a-11cb-4e5c-b291-9b8c833c4ddf.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mt-shirt/950ed785-66d7-4f9b-99e7-925641ecad2b.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 't-shirt/950ed785-66d7-4f9b-99e7-925641ecad2b.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mt-shirt/99fdccb7-216b-46ce-88fd-15e79bccdeac.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 't-shirt/99fdccb7-216b-46ce-88fd-15e79bccdeac.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mt-shirt/b7cefd6f-18ea-4135-b6a0-aaf493fbbe94.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 't-shirt/b7cefd6f-18ea-4135-b6a0-aaf493fbbe94.jpg'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mt-shirt/fb5dd646-6a9e-4666-ab78-74b463431f54.jpg: ignoring corrupt image/label: [Errno 2] No such file or directory: 't-shirt/fb5dd646-6a9e-4666-ab78-74b463431f54.jpg'\n",
      "WARNING ⚠️ \u001b[34m\u001b[1mtrain: \u001b[0mNo labels found in dress.cache. See https://docs.ultralytics.com/datasets for dataset formatting guidance.\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: dress.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No valid images found in dress.cache. Images with incorrectly formatted labels are ignored. See https://docs.ultralytics.com/datasets for dataset formatting guidance.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(train_txt_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     15\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(total_frames))\n\u001b[0;32m---> 18\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_yolo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcycle_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_yaml_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[36], line 7\u001b[0m, in \u001b[0;36mtrain_yolo\u001b[0;34m(cycle_name, data_yaml_path, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m YOLO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myolo11n.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#Treinar modelo\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_yaml_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcycle_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlightly_selection2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# device=[0, 1]\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/active-vehicle-detection/venv/lib/python3.10/site-packages/ultralytics/engine/model.py:799\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mhub_session \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[0;32m--> 799\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n",
      "File \u001b[0;32m~/active-vehicle-detection/venv/lib/python3.10/site-packages/ultralytics/engine/trainer.py:227\u001b[0m, in \u001b[0;36mBaseTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 227\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/active-vehicle-detection/venv/lib/python3.10/site-packages/ultralytics/engine/trainer.py:348\u001b[0m, in \u001b[0;36mBaseTrainer._do_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m world_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_ddp(world_size)\n\u001b[0;32m--> 348\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    350\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader)  \u001b[38;5;66;03m# number of batches\u001b[39;00m\n\u001b[1;32m    351\u001b[0m nw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m*\u001b[39m nb), \u001b[38;5;241m100\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mwarmup_epochs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# warmup iterations\u001b[39;00m\n",
      "File \u001b[0;32m~/active-vehicle-detection/venv/lib/python3.10/site-packages/ultralytics/engine/trainer.py:307\u001b[0m, in \u001b[0;36mBaseTrainer._setup_train\u001b[0;34m(self, world_size)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# Dataloaders\u001b[39;00m\n\u001b[1;32m    306\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(world_size, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dataloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLOCAL_RANK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m}:\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;66;03m# Note: When training DOTA dataset, double batch size could get OOM on images with >2000 objects.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtest_loader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_dataloader(\n\u001b[1;32m    313\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    314\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    315\u001b[0m         rank\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    316\u001b[0m         mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    317\u001b[0m     )\n",
      "File \u001b[0;32m~/active-vehicle-detection/venv/lib/python3.10/site-packages/ultralytics/models/yolo/detect/train.py:84\u001b[0m, in \u001b[0;36mDetectionTrainer.get_dataloader\u001b[0;34m(self, dataset_path, batch_size, rank, mode)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m}, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMode must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch_distributed_zero_first(rank):  \u001b[38;5;66;03m# init dataset *.cache only once if DDP\u001b[39;00m\n\u001b[0;32m---> 84\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m shuffle \u001b[38;5;241m=\u001b[39m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m shuffle:\n",
      "File \u001b[0;32m~/active-vehicle-detection/venv/lib/python3.10/site-packages/ultralytics/models/yolo/detect/train.py:67\u001b[0m, in \u001b[0;36mDetectionTrainer.build_dataset\u001b[0;34m(self, img_path, mode, batch)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03mBuild YOLO Dataset for training or validation.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    (Dataset): YOLO dataset object configured for the specified mode.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mint\u001b[39m(de_parallel(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\u001b[38;5;241m.\u001b[39mstride\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuild_yolo_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/active-vehicle-detection/venv/lib/python3.10/site-packages/ultralytics/data/build.py:127\u001b[0m, in \u001b[0;36mbuild_yolo_dataset\u001b[0;34m(cfg, img_path, batch, data, mode, rect, stride, multi_modal)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Build and return a YOLO dataset based on configuration parameters.\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m dataset \u001b[38;5;241m=\u001b[39m YOLOMultiModalDataset \u001b[38;5;28;01mif\u001b[39;00m multi_modal \u001b[38;5;28;01melse\u001b[39;00m YOLODataset\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimg_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimgsz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimgsz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m    \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# augmentation\u001b[39;49;00m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# TODO: probably add a get_hyps_from_cfg function\u001b[39;49;00m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrect\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrect\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# rectangular batches\u001b[39;49;00m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43msingle_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_cls\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolorstr\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmode\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfraction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/active-vehicle-detection/venv/lib/python3.10/site-packages/ultralytics/data/dataset.py:88\u001b[0m, in \u001b[0;36mYOLODataset.__init__\u001b[0;34m(self, data, task, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_segments \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_keypoints), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not use both segments and keypoints.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchannels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchannels\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/active-vehicle-detection/venv/lib/python3.10/site-packages/ultralytics/data/base.py:116\u001b[0m, in \u001b[0;36mBaseDataset.__init__\u001b[0;34m(self, img_path, imgsz, cache, augment, hyp, prefix, rect, batch_size, stride, pad, single_cls, classes, fraction, channels)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcv2_flag \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE \u001b[38;5;28;01mif\u001b[39;00m channels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_img_files(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_path)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_labels(include_class\u001b[38;5;241m=\u001b[39mclasses)  \u001b[38;5;66;03m# single_cls and include_class\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mni \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels)  \u001b[38;5;66;03m# number of images\u001b[39;00m\n",
      "File \u001b[0;32m~/active-vehicle-detection/venv/lib/python3.10/site-packages/ultralytics/data/dataset.py:188\u001b[0m, in \u001b[0;36mYOLODataset.get_labels\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m labels \u001b[38;5;241m=\u001b[39m cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m labels:\n\u001b[0;32m--> 188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid images found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcache_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Images with incorrectly formatted labels are ignored. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHELP_URL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mim_files \u001b[38;5;241m=\u001b[39m [lb[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mim_file\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m lb \u001b[38;5;129;01min\u001b[39;00m labels]  \u001b[38;5;66;03m# update im_files\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# Check if the dataset is all boxes or all segments\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No valid images found in dress.cache. Images with incorrectly formatted labels are ignored. See https://docs.ultralytics.com/datasets for dataset formatting guidance."
     ]
    }
   ],
   "source": [
    "total_frames = []\n",
    "for file in tag_files:\n",
    "    with open(DATASET_PATH + '/' + file, 'r') as f:\n",
    "        frames = [linha.strip() for linha in f if linha.strip()]\n",
    "        print(f'qtd de linhas: {len(frames)}')\n",
    "        total_frames.extend(frames)\n",
    "\n",
    "    cycle_name = file.split('.txt')[0]\n",
    "    print(f\"\\n🚀 Preparando ciclo {cycle_name} com {len(frames)} imagens\")\n",
    "\n",
    "    config_path = prepare_yolo_dataset(cycle_name, file, DATASET_PATH)\n",
    "\n",
    "    train_txt_path = config_path / f\"{cycle_name}_acumulado.txt\"\n",
    "    with open(train_txt_path, 'w') as f:\n",
    "        f.write('\\n'.join(total_frames))\n",
    "\n",
    "\n",
    "    results = train_yolo(cycle_name, data_yaml_path=str(config_path / \"data.yaml\"), epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "19fdb2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ciclo1'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_path.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2b103b20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config/ciclo1/data.yaml'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(config_path / \"data.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a5a4b33c",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOCAL\t\t  config\t     requirements.txt\t    utils\n",
      "LICENSE\t\t  lightly\t     schedule_runs_1.ipynb  venv\n",
      "README.md\t  lightly-api\t     schedule_runs_5.ipynb  yolo11n.pt\n",
      "antigos\t\t  lightly_selection  src\n",
      "clothing_dataset  predictions.zip    train_yolo.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b920420",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
